{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Noteboook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook used to train models on Compute Canada Cluster**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../preprocessing')\n",
    "sys.path.append('../instanciate_models')\n",
    "sys.path.append('../models')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "\n",
    "from utils.data_utils import convert_niigz_to_numpy, prepare_dataset_for_training_local\n",
    "from utils.visualization import visualize_infered_labels\n",
    "from preprocessing.data_loader import load_data, load_test_data\n",
    "from instanciate_models.make_unet_resblock2 import make_unet_resblock2\n",
    "from models.inference.inference import model_inference, download_model_wandb\n",
    "from log_wandb import log_wandb_run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy files already exist\n",
      "Preparing dataset for training...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "task_name = \"Task02_Heart\"\n",
    "\n",
    "# paths\n",
    "dataset_path = \"../dataset\"\n",
    "task_folder_path = os.path.join(dataset_path, task_name)\n",
    "\n",
    "# load dataset.json file\n",
    "with open(os.path.join(task_folder_path, \"dataset.json\"), \"r\") as f:\n",
    "    dataset_json = json.load(f)\n",
    "\n",
    "# to start training, should have this structure:\n",
    "# task_folder_path\n",
    "#     ├── train_val\n",
    "#     │   ├── image_001.nii.gz\n",
    "#     │   ├── image_002.nii.gz\n",
    "#     │   ├── ...\n",
    "#     │   ├── label_002.nii.gz\n",
    "#     │   ├── label_001.nii.gz\n",
    "#     │   ├── ...\n",
    "#     ├── test\n",
    "#     │   ├── image_001.nii.gz\n",
    "#     │   ├── image_002.nii.gz\n",
    "#     │   ├── ...\n",
    "#     │── dataset.json\n",
    "\n",
    "# check if the task folder is ready for training\n",
    "if not os.path.exists(os.path.join(task_folder_path, \"train_val\")) and not os.path.exists(os.path.join(task_folder_path, \"test\")):\n",
    "    assert os.path.exists(os.path.join(task_folder_path, \"imagesTr\")), \"imagesTr folder does not exist\"\n",
    "    assert os.path.exists(os.path.join(task_folder_path, \"labelsTr\")), \"labelsTr folder does not exist\"\n",
    "    assert os.path.exists(os.path.join(task_folder_path, \"imagesTs\")), \"imagesTs folder does not exist\"\n",
    "    assert os.path.exists(os.path.join(task_folder_path, \"dataset.json\")), \"dataset.json file does not exist\"\n",
    "    if sorted(os.listdir(os.path.join(task_folder_path, \"imagesTr\")))[0].endswith(\".nii.gz\"):\n",
    "        print(\"Converting nii.gz to numpy...\")\n",
    "        convert_niigz_to_numpy(task_folder_path)\n",
    "        print(\"Done\")\n",
    "    elif sorted(os.listdir(os.path.join(task_folder_path, \"imagesTr\")))[0].endswith(\".npy\"):\n",
    "        assert len(os.listdir(os.path.join(task_folder_path, \"imagesTr\")))==dataset_json[\"numTraining\"], \"Number of training images does not match dataset.json\"\n",
    "        assert len(os.listdir(os.path.join(task_folder_path, \"labelsTr\")))==dataset_json[\"numTraining\"], \"Number of training labels does not match dataset.json\"\n",
    "        assert len(os.listdir(os.path.join(task_folder_path, \"imagesTs\")))==dataset_json[\"numTest\"], \"Number of test images does not match dataset.json\"\n",
    "        print(\"Numpy files already exist\")\n",
    "    print(\"Preparing dataset for training...\")\n",
    "    prepare_dataset_for_training_local(task_folder_path)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    assert len(os.listdir(os.path.join(task_folder_path, \"train_val\")))==dataset_json[\"numTraining\"]*2, \"Number of training images and labels does not match dataset.json\"\n",
    "    assert len(os.listdir(os.path.join(task_folder_path, \"test\")))==dataset_json[\"numTest\"], \"Number of test images does not match dataset.json\"\n",
    "    print(\"Task folder is already ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1, 128, 128, 128)\n",
      "train dataloader len: 16\n",
      "val dataloader len: 4\n"
     ]
    }
   ],
   "source": [
    "# init parameters\n",
    "batch_size = 2\n",
    "num_classes = len(dataset_json[\"labels\"])\n",
    "shuffle = True\n",
    "normalize = True\n",
    "resize = (128, 128, 128)\n",
    "transform = None\n",
    "\n",
    "# load dataloaders\n",
    "train_dataloader, val_dataloader = load_data(task_folder_path, \n",
    "                                             batch_size=batch_size, \n",
    "                                             num_classes=num_classes, \n",
    "                                             shuffle=shuffle,\n",
    "                                             normalize=normalize,\n",
    "                                             resize=resize,\n",
    "                                             transform=transform)\n",
    "\n",
    "# print shapes\n",
    "input_example = train_dataloader.dataset[0][0].unsqueeze(0)\n",
    "input_shape = tuple(list(input_example[0].shape))\n",
    "print(\"input shape:\", input_shape)\n",
    "print(\"train dataloader len:\", len(train_dataloader.dataset))\n",
    "print(\"val dataloader len:\", len(val_dataloader.dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cpu\n",
      "UNet(\n",
      "  (predict_softmax): Softmax(dim=1)\n",
      "  (encoder): ConvEncoder(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (1): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (3): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (4): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(380, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(380, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (5): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(380, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downscaling_layers): ModuleList(\n",
      "      (0-4): 5 x MaxPool3dDownscale(\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvDecoder(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(760, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(380, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(380, 380, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(380, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (1): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (3): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (4): ResConvBlock(\n",
      "        (conv_block_1): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_2): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (conv_block_3): Conv3DDropoutNormActivation(\n",
      "          (convolution): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (dropout): Dropout3d(p=0, inplace=False)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "          (normalization): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upscaling_layers): ModuleList(\n",
      "      (0): TransposeConv3dUpsample(\n",
      "        (transpose_conv): ConvTranspose3d(512, 380, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      )\n",
      "      (1): TransposeConv3dUpsample(\n",
      "        (transpose_conv): ConvTranspose3d(380, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      )\n",
      "      (2): TransposeConv3dUpsample(\n",
      "        (transpose_conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      )\n",
      "      (3): TransposeConv3dUpsample(\n",
      "        (transpose_conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      )\n",
      "      (4): TransposeConv3dUpsample(\n",
      "        (transpose_conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "# setup device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# instantiate model\n",
    "model = make_unet_resblock2(0).to(device)\n",
    "\n",
    "# print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 1, 128, 128, 128])\n",
      "output shape unet: torch.Size([1, 2, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "output = model(input_example.to(device))\n",
    "print('input shape:', input_example.shape)\n",
    "print('output shape unet:', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "# init params\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-7)\n",
    "criterion = DiceCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=20)\n",
    "run_name = f\"{model.__class__.__name__}_{task_name}\"\n",
    "\n",
    "# train model\n",
    "log_wandb_run(model, \n",
    "              train_dataloader, \n",
    "              val_dataloader, \n",
    "              batch_size=batch_size,\n",
    "              num_classes=num_classes, \n",
    "              num_epochs=3, \n",
    "              patience=100, \n",
    "              optimizer=optimizer, \n",
    "              criterion=criterion, \n",
    "              scheduler=scheduler,\n",
    "              segmentation_ouput=True,\n",
    "              run_name=run_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "# load model from wandb\n",
    "model = download_model_wandb(make_unet_resblock2(0), \"enzymes\", \"ift6759_project\", \"UNet\", \"v14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init parameters\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "normalize = True\n",
    "resize = (128, 128, 128)\n",
    "transform = None\n",
    "output_folder = os.path.join(\"inference\", task_name)\n",
    "output_filenames = sorted(os.listdir(os.path.join(task_folder_path, \"test\")))\n",
    "output_filenames_idx = [filename[-7:-4] for filename in output_filenames]\n",
    "\n",
    "# load test dataloader\n",
    "test_dataloader = load_test_data(task_folder_path,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle,\n",
    "                                 normalize=normalize,\n",
    "                                 resize=resize,\n",
    "                                 transform=transform)\n",
    "\n",
    "# perform inference on model and save output labels\n",
    "model_inference(model,\n",
    "                test_dataloader,\n",
    "                task_folder_path,\n",
    "                task_name,\n",
    "                output_folder,\n",
    "                output_filenames_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataloader\n",
    "test_dataloader = load_test_data(task_folder_path,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False,\n",
    "                                 normalize=False,\n",
    "                                 resize=None,\n",
    "                                 transform=None)\n",
    "\n",
    "labels_path = os.path.join(output_folder, sorted(os.listdir(output_folder))[-1])\n",
    "visualize_infered_labels(test_dataloader, labels_path, figsize=(5, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
